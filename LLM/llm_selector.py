import json
from tools.paths import AVAILABLE_OPTION_PATH
from LLM.llama3_groq import call_llm as call_llm_groq
from LLM.gpt_openai import call_llm as call_llm_openai
from LLM.claude_opr import call_llm as call_llm_claude

# âœ… LLM ì´ë¦„ â†’ í•¨ìˆ˜ ë§¤í•‘
LLM_MAP = {
    "groq": call_llm_groq,
    "openai": call_llm_openai,
    "claude": call_llm_claude,
    "openrouter": call_llm_claude,
}

def get_available_llms():
    """ available_option.jsonì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ LLM ëª©ë¡ ë°˜í™˜ """
    if not AVAILABLE_OPTION_PATH.exists():
        return []
    with open(AVAILABLE_OPTION_PATH, encoding="utf-8") as f:
        data = json.load(f)
    return [llm.lower() for llm in data.get("LLM", [])]

def call_llm(prompt: str, llm_name: str, temperature: float = 0.6, **kwargs) -> str:
    """
    LLM ì´ë¦„ì— ë”°ë¼ ìë™ìœ¼ë¡œ ì ì ˆí•œ call_llm í•¨ìˆ˜ ì—°ê²°
    + ì¶”ê°€ ì¸ì(kwargs)ëŠ” í•˜ìœ„ LLMì—ê²Œ ê·¸ëŒ€ë¡œ ì „ë‹¬
    """
    key = llm_name.lower()

    if key not in get_available_llms():
        raise ValueError(f"âŒ available_option.jsonì— ì •ì˜ë˜ì§€ ì•Šì€ LLMì…ë‹ˆë‹¤: {llm_name}")

    for name, func in LLM_MAP.items():
        if name in key:
            return func(prompt=prompt, llm_name=llm_name, temperature=temperature, **kwargs)  # âœ… ì•ˆì „í•˜ê²Œ ì „ë‹¬

    raise ValueError(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” LLM: {llm_name}")


# ğŸ” q_gen.py í˜¸í™˜ì„± ìœ ì§€ìš© export
generate_by_llm = call_llm
