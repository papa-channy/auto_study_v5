# ğŸ“ scripts/run_all.py

import sys, os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scripts.base_import import add_root_path
add_root_path()

# ğŸ“Œ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
import json
from tools.paths import SETTING_JSON_PATH
with open(SETTING_JSON_PATH, encoding="utf-8") as f:
    config = json.load(f)

# âœ… ì‚¬ìš©ì ì„¤ì •ê°’
tool_list = list(config["study_matrix&difficulty"].keys())
difficulty_map = config["study_matrix&difficulty"]
llm = config["LLM"]
dataset_list = config["DATASET"]
count = config["count"]

# âœ¨ ê¸°ëŠ¥ import
from generator.core.q_main import run_pipeline
from tools.store_manager import (
    save_structured_questions,
    save_llm_tags,
    save_comparison_log
)
from logs.log_reporter import save_log_report
from notion.notion_uploader import NotionUploader
from tools.clean_cache import clean_cache

# 1ï¸âƒ£ ì„¤ì • ì¶œë ¥
print("ğŸ“Œ ì„¤ì • ìš”ì•½")
print(f"- ë„êµ¬: {tool_list}")
print(f"- ë‚œì´ë„: {difficulty_map}")
print(f"- LLM: {llm}")
print(f"- ë°ì´í„°ì…‹: {dataset_list}")
print(f"- í˜¸ì¶œ íšŸìˆ˜: {count}")

# 2ï¸âƒ£ ì§ˆë¬¸ ìƒì„± ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (a ~ p)
o_df, i_df, p_list = run_pipeline(
    tool_list, dataset_list, difficulty_map, count, llm
)

# 3ï¸âƒ£ ê²°ê³¼ ì €ì¥
save_structured_questions(o_df)
save_llm_tags(i_df)
save_comparison_log(p_list)

# 4ï¸âƒ£ ë¦¬í¬íŠ¸ ì €ì¥
save_log_report()

# 5ï¸âƒ£ Notion ì—…ë¡œë“œ
uploader = NotionUploader()
uploader.upload()

# 6ï¸âƒ£ ìºì‹œ ì •ë¦¬
clean_cache()
